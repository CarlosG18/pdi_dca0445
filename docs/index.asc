:numbered:
:author: CARLOS GABRIEL MEDEIROS DA SILVA
:icons:
:experimental:
:stem:
:imagesdir: ./figs
:toc: left
:doctype: book
:source-highlighter: pygments
:caution-caption: Cuidado
:important-caption: Importante
:note-caption: Nota
:tip-caption: Dica
:warning-caption: Aviso
:appendix-caption: Apêndice
:example-caption: Exemplo
:figure-caption: Figura
:listing-caption: Listagem
:table-caption: Tabela
:toc-title: Sumário
:preface-title: Prefácio
:version-label: Versão
:last-update-label: Última atualização

= DCA0445: Processamento Digital de Imagens =

Carlos Gabriel <c.gabriel.abc18@gmail.com>

== Atividades Unidade 1

=== Prática 1 - Manipulando pixels em uma imagem (regions.cpp)

Foi desenvolvido um programa chamado "regions.cpp" com base no código "pixels.cpp" disponibilizado https://agostinhobritojr.github.io/tutorial/pdi/pixels.html[aqui]. Esse novo programa solicita ao usuário que informe as coordenadas de dois pontos, P1 e P2, dentro dos limites da imagem fornecida. A região delimitada pelo retângulo de vértices opostos nesses pontos é exibida com o efeito negativo aplicado, destacando essa área específica da imagem. 

O código utilizado para realizar essa prática esta descrito logo abaixo:

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

struct Point {
    int x;
    int y;

    Point(int value_x, int value_y) : x(value_x), y(value_y) {}
};

int main(int argc, char** argv) {
    cv::Mat image;

    if (argc != 5) {
        std::cout << "Uso: ./regions <P1_x> <P1_y> <P2_x> <P2_y>" << std::endl;
        return -1;
    }

    // Lendo os argumentos da linha de comando
    int P1_x = std::stoi(argv[1]);
    int P1_y = std::stoi(argv[2]);
    int P2_x = std::stoi(argv[3]);
    int P2_y = std::stoi(argv[4]);

    //verificação da região
    if (P1_x >= P2_x || P1_y >= P2_y){
        std::cout << "A região informada não está coerente!" << std::endl;
        return -1;
    }

    image = cv::imread("biel.png", cv::IMREAD_GRAYSCALE);
    if (!image.data) std::cout << "nao abriu bolhas.png" << std::endl;

    cv::namedWindow("janela", cv::WINDOW_AUTOSIZE);
    
    // Criando os pontos
    Point point1(P1_x, P1_y);
    Point point2(P2_x, P2_y);

    for (int i = point1.x; i < point2.x; i++) {
        for (int j = point1.y; j < point2.y; j++) {
            // Certificando-se de que os índices estão dentro dos limites da imagem
            if (j >= 0 && j < image.rows && i >= 0 && i < image.cols) {
                image.at<uchar>(i, j) = 255 - image.at<uchar>(i, j);
            }
        }
    }
    cv::imshow("janela", image);
    cv::waitKey();
    return 0;
}
----

==== Comentários sobre o código

* Foi criado uma **__struct__** basica para representar os pontos;

* Com os pontos coletados, foi feito uma varedura entre os pixels da area informada e atribuido o negativo a partir da operação **__image.at<uchar>(i, j) = 255 - image.at<uchar>(i, j);__**;

A Figura 1 ilustra o resultado obtido:

[#image-result1]
.resultado_pratica1.png
image::resultado_pratica1.png[Resultado da Prática 1]

---

=== Prática 2 - Manipulando pixels em uma imagem (trocaregioes.cpp)

Foi desenvolvido um programa chamado "trocaregioes.cpp" com base no código "pixels.cpp" disponibilizado https://agostinhobritojr.github.io/tutorial/pdi/pixels.html[aqui]. Esse novo programa realiza uma transformação na imagem fornecida, trocando os quadrantes dispostos em diagonal. O usuário fornece uma imagem, e o programa divide-a em quatro quadrantes iguais. Em seguida, os quadrantes localizados em posições diagonais são trocados entre si, gerando uma nova composição visual onde a parte superior esquerda se alterna com a inferior direita e a parte superior direita com a inferior esquerda. Essa modificação altera a disposição da imagem, destacando novos detalhes na estrutura visual.

O código utilizado para realizar essa prática esta descrito logo abaixo:

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv) {
    cv::Mat image;
    cv::Rect rect(20, 50, 30, 30);

    image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);
    if (!image.data) std::cout << "nao abriu!" << std::endl;

    // obtendo os quadrantes
    cv::Mat q1 = image(cv::Rect(0,0,image.cols/2,image.rows/2));
    cv::Mat q2 = image(cv::Rect(image.cols/2,0,image.cols/2,image.rows/2));
    cv::Mat q3 = image(cv::Rect(0,image.rows/2,image.cols/2,image.rows/2));
    cv::Mat q4 = image(cv::Rect(image.rows/2,image.cols/2,image.cols/2,image.rows/2));

    cv::Mat RowUp, RowDown, FinalImage;

    cv::hconcat(q4, q3, RowUp); // concatena horizontalmente duas matrizes (images)
    cv::hconcat(q2, q1, RowDown); // concatena horizontalmente duas matrizes (images)
    cv::vconcat(RowUp, RowDown, FinalImage); // concatena verticalmente duas matrizes (images)
    
    cv::namedWindow("janela", cv::WINDOW_AUTOSIZE);

    cv::imshow("janela", FinalImage);
    cv::waitKey();
    return 0;
}
----

==== Comentários sobre o código

* A imagem foi separada em 4 sub-imagens definindo as imagens de cada quadrante;

* Em seguida foi feito a concatenação das duas imagens do quadrante na horientação horizontal do **q4->q3** e do **q2->q1**;

* Por fim é feito a concatenação vertical das duas linhas concatenadas gerando a imagem com os quadrantes diagonais trocados.

A Figura 2 ilustra o resultado obtido:

[#image-result2]
.resultado_pratica2.png
image::resultado_pratica2.png[Resultado da Prática 2]

=== Prática 3 - Filtragem no domínio espacial I - Convolução

==== Exercicio 1 - (convolucao2.cpp)

Neste exercício, foi desenvolvido um programa para realizar a convolução com o filtro da média, aplicando máscaras de tamanhos 11×11 e 21×21 pixels. Os resultados obtidos foram comparados com os do filtro de tamanho 3×3 pixels.

Foi criado uma função para criar as máscaras com a dimensão gênerica, comos podemos ver no código abaixo:

[[create_mask, Fun]]
[source,cpp]
.convolucao2.cpp
----
float* create_mask(int dimensao,std::string tipo){
  float** matriz = new float*[dimensao*dimensao];
  int limit_inf =(dimensao-1)/2;
  int limit_sup = (dimensao-1)/2;
  int elemento_central_laplacian = 0;
  

  for (int i = 0; i < dimensao; i++) {
        matriz[i] = new float[dimensao];
  }

  for(int i=0; i < dimensao; i++){
    for(int j=0; j < dimensao; j++){
      if(tipo == "media"){
        matriz[i][j] = 1.0/(dimensao*dimensao);
      }else if(tipo == "gauss"){
        float sigma = dimensao / 3.0;
        float x = i - dimensao / 2;
        float y = j - dimensao / 2;
        matriz[i][j] = exp(-(x * x + y * y) / (2 * sigma * sigma)) / (2 * M_PI * sigma * sigma);
      }else if(tipo == "horizontal"){
        if (j == 0) {
          matriz[i][j] = -1;
          if(i == (dimensao-1)/2){
            matriz[i][j] = -2;
          }
        } else if (j == dimensao-1) {
          matriz[i][j] = 1;
          if(i == (dimensao-1)/2){
            matriz[i][j] = 2;
          }
        } else {
          matriz[i][j] = 0;
        }
      }else if(tipo == "vertical"){
        if (i == 0) {
          matriz[i][j] = -1;
          if(j == (dimensao-1)/2){
            matriz[i][j] = -2;
          }
        } else if (i == dimensao-1) {
          matriz[i][j] = 1;
          if(j == (dimensao-1)/2){
            matriz[i][j] = 2;
          }
        } else {
          matriz[i][j] = 0;
        }
      }else if(tipo == "laplacian"){
        if(j < limit_inf || j > limit_sup){
          matriz[i][j] = 0;
        }else{
          matriz[i][j] = -1;
          elemento_central_laplacian += 1;
        }
      }
    }
    std::cout << limit_inf << " " << limit_sup << std::endl;
    if(i < (dimensao-1)/2){
      limit_inf -= 1;
      limit_sup += 1;
    }else{
      limit_inf += 1;
      limit_sup -= 1;
    }
  }

  if(tipo == "laplacian"){
    elemento_central_laplacian -= 1;
    matriz[(dimensao-1)/2][(dimensao-1)/2] = elemento_central_laplacian;
  }


  float* vetor = transform_matriz_for_vetor(matriz, dimensao);
  
  // liberando memoria da alocação da matriz
  for (int i = 0; i < dimensao; i++) {
    delete[] matriz[i];
  }
  delete[] matriz;

  return vetor;
}
----

Com isso foi usado o código fornecido pelo exemplo e feito as seguintes alterações para aplicar a convolução na imagem capturada pela webcam:

[[main, Fun]]
[source,cpp]
.convolucao2.cpp
----
int main(int, char* argv[]) {
  int dimensao = std::stoi(argv[1]);

  if (dimensao % 2 == 0){
    return -1;
  }

  cv::VideoCapture cap;
  int camera;
  float* media = create_mask(dimensao, "media");
  float* gauss = create_mask(dimensao, "gauss");
  float* horizontal = create_mask(dimensao, "horizontal");
  float* vertical = create_mask(dimensao, "vertical");
  float* laplacian = create_mask(dimensao, "laplacian");
  imprimir_vetor(laplacian, dimensao);

  cv::Mat frame, framegray, frame32f, frameFiltered;
  cv::Mat mask(dimensao, dimensao, CV_32F);
  cv::Mat result;
  double width, height;
  int absolut;
  char key;

  camera = cameraEnumerator();
  cap.open(camera);

  if (!cap.isOpened()) 
    return -1;

  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);

  cv::namedWindow("filtroespacial", cv::WINDOW_NORMAL);
  cv::namedWindow("original", cv::WINDOW_NORMAL);

  mask = cv::Mat(dimensao, dimensao, CV_32F, media);

  absolut = 1;  // calcula absoluto da imagem

  for (;;) {
    cap >> frame;  // captura nova imagem da camera
    cv::cvtColor(frame, framegray, cv::COLOR_BGR2GRAY);
    cv::flip(framegray, framegray, 1);
    cv::imshow("original", framegray);
    framegray.convertTo(frame32f, CV_32F);
    cv::filter2D(frame32f, frameFiltered, frame32f.depth(), mask, cv::Point(1, 1), cv::BORDER_REPLICATE);
    if (absolut) {
      frameFiltered = cv::abs(frameFiltered);
    }

    frameFiltered.convertTo(result, CV_8U);

    cv::imshow("filtroespacial", result);

    key = (char)cv::waitKey(10);
    if (key == 27) break;  // tecla ESC pressionada!
    switch (key) {
      case 'a':
        absolut = !absolut;
        break;
      case 'm':
        mask = cv::Mat(dimensao,dimensao, CV_32F, media);
        printmask(mask);
        break;
      case 'g':
        mask = cv::Mat(dimensao, dimensao, CV_32F, gauss);
        printmask(mask);
        break;
      case 'h':
        mask = cv::Mat(dimensao, dimensao, CV_32F, horizontal);
        printmask(mask);
        break;
      case 'v':
        mask = cv::Mat(dimensao, dimensao, CV_32F, vertical);
        printmask(mask);
        break;
      case 'l':
        mask = cv::Mat(dimensao, dimensao, CV_32F, laplacian);
        printmask(mask);
        break;
    }
  }
  return 0;
}
----

==== Comentários sobre o código

* Básicamente o que irá mudar no código sera apenas as mascaras de convolução.

A Figura 3 ilustra o resultado obtido:

[#image-result31]
.media.png
image::media.png[Resultado da Prática 3 - exercicio 1]

Com isso, podemos notar que quanto maior a dimensão da máscara, mais intenso o efeito relacionando ao filtro aplicado é maior. em alguns casos isso pode gerar algo até irreconhecivel como os filtros horizontal, vertical e laplaciano de dimensão 21x21.

==== Exercicio 2 - (depthffield.cpp)

Neste exercício, foi implementado um programa chamado depthoffield.cpp com o objetivo de simular uma correção para o efeito de profundidade de campo em imagens digitais, especialmente em cenas sem movimento. O programa inicia capturando um frame do vídeo apresentado, convertendo-o em tons de cinza para facilitar a análise. Em seguida, uma matriz é criada para armazenar os valores máximos dos laplacianos aplicados, que destacam áreas de maior contraste na imagem.

Um filtro laplaciano de tamanho 3×3 pixels é aplicado à imagem em tons de cinza. O resultado é comparado com a matriz de máximos para identificar os pixels que apresentam maior valor de contraste. Esses pixels selecionados são copiados para a imagem de saída, preservando as cores originais da imagem capturada, enquanto o restante da imagem é deixado desfocado. Ao final, a imagem de saída é exibida, destacando as áreas mais nítidas, como uma simulação de profundidade de campo ajustada.

[[depth, Fun]]
[source,cpp]
.depthoffield.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv) {
    // Carregar o vídeo
    cv::VideoCapture cap;
    double width, height;
    cv::Mat frame, framegray, frameFiltered, frame32f, image_final;
    cv::Mat mask(3, 3, CV_32F);
    cv::Mat maximos8U, maximosColor;
    cv::Mat resultado;

    float laplacian[] = {0, -1, 0, -1, 4, -1, 0, -1, 0};
    mask = cv::Mat(3, 3, CV_32F, laplacian);

    cap.open(argv[1]);
    if (!cap.isOpened()) {
        std::cerr << "Erro ao abrir o vídeo!" << std::endl;
        return -1;
    }

    //obtendo as dimensões do video
    width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
    height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

    // Inicializar a matriz de máximos do laplaciano
    cv::Mat maximos = cv::Mat(height, width, CV_32F, cv::Scalar(0));

    while (cap.read(frame)) { // Capturar o frame
        if (frame.empty()) {
            std::cerr << "Erro: Frame vazio!" << std::endl;
            break;
        }

        // Converter o frame para tons de cinza
        cv::cvtColor(frame, framegray, cv::COLOR_BGR2GRAY);
        framegray.convertTo(frame32f, CV_32F);

        // Fazer a convolução com a máscara 3x3 laplaciana
        cv::filter2D(frame32f, frameFiltered, frame32f.depth(), mask, cv::Point(1, 1), cv::BORDER_REPLICATE);

        // Comparar com o valor da matriz dos máximos do laplaciano
        for (int i = 0; i < height; i++) {
            for (int j = 0; j < width; j++) {
                if (frameFiltered.at<float>(i, j) > maximos.at<float>(i, j)) {
                    maximos.at<float>(i, j) = frameFiltered.at<float>(i, j);
                }
            }
        }

        // Converter maximos para o mesmo tipo e número de canais de frame antes de somar
        
        maximos.convertTo(maximos8U, CV_8U);
        cv::cvtColor(maximos8U, maximosColor, cv::COLOR_GRAY2BGR); // Converte para 3 canais

        cv::imshow("Resultado", maximosColor);

        if (cv::waitKey(30) >= 0) break;
    }

    if (cv::imwrite("output_image.jpg", maximosColor)) {
        std::cout << "Imagem salva com sucesso como 'output_image.jpg'" << std::endl;
    } else {
        std::cerr << "Erro ao salvar a imagem!" << std::endl;
    }

    return 0;
}
----

==== Comentários sobre o código

não foi obtido a conversão da cor do video original.

A Figura 4 ilustra o resultado obtido:

[#image-result32]
.output_image.jpg
image::media.png[Resultado da Prática 3 - exercicio 2]

== Bibliografia ==
[bibliography]
- Stephen Prata. 'C++ Primer Plus'. Addison-Wesley. 1990. 2 ed.
- http://www.cplusplus.com. 'Principal portal de desenvolvimento e referência para programação em C++'.


