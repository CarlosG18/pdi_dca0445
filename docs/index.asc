:numbered:
:author: CARLOS GABRIEL MEDEIROS DA SILVA
:icons:
:experimental:
:stem:
:imagesdir: ./figs
:toc: left
:doctype: book
:source-highlighter: pygments
:caution-caption: Cuidado
:important-caption: Importante
:note-caption: Nota
:tip-caption: Dica
:warning-caption: Aviso
:appendix-caption: Apêndice
:example-caption: Exemplo
:figure-caption: Figura
:listing-caption: Listagem
:table-caption: Tabela
:toc-title: Sumário
:preface-title: Prefácio
:version-label: Versão
:last-update-label: Última atualização

= DCA0445: Processamento Digital de Imagens =

Carlos Gabriel <c.gabriel.abc18@gmail.com>

== Atividades Unidade 1

=== Prática 1 - Manipulando pixels em uma imagem (regions.cpp)

Foi desenvolvido um programa chamado "regions.cpp" com base no código "pixels.cpp" disponibilizado https://agostinhobritojr.github.io/tutorial/pdi/pixels.html[aqui]. Esse novo programa solicita ao usuário que informe as coordenadas de dois pontos, P1 e P2, dentro dos limites da imagem fornecida. A região delimitada pelo retângulo de vértices opostos nesses pontos é exibida com o efeito negativo aplicado, destacando essa área específica da imagem. 

O código utilizado para realizar essa prática esta descrito logo abaixo:

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

struct Point {
    int x;
    int y;

    Point(int value_x, int value_y) : x(value_x), y(value_y) {}
};

int main(int argc, char** argv) {
    cv::Mat image;

    if (argc != 5) {
        std::cout << "Uso: ./regions <P1_x> <P1_y> <P2_x> <P2_y>" << std::endl;
        return -1;
    }

    // Lendo os argumentos da linha de comando
    int P1_x = std::stoi(argv[1]);
    int P1_y = std::stoi(argv[2]);
    int P2_x = std::stoi(argv[3]);
    int P2_y = std::stoi(argv[4]);

    //verificação da região
    if (P1_x >= P2_x || P1_y >= P2_y){
        std::cout << "A região informada não está coerente!" << std::endl;
        return -1;
    }

    image = cv::imread("biel.png", cv::IMREAD_GRAYSCALE);
    if (!image.data) std::cout << "nao abriu bolhas.png" << std::endl;

    cv::namedWindow("janela", cv::WINDOW_AUTOSIZE);
    
    // Criando os pontos
    Point point1(P1_x, P1_y);
    Point point2(P2_x, P2_y);

    for (int i = point1.x; i < point2.x; i++) {
        for (int j = point1.y; j < point2.y; j++) {
            // Certificando-se de que os índices estão dentro dos limites da imagem
            if (j >= 0 && j < image.rows && i >= 0 && i < image.cols) {
                image.at<uchar>(i, j) = 255 - image.at<uchar>(i, j);
            }
        }
    }
    cv::imshow("janela", image);
    cv::waitKey();
    return 0;
}
----

==== Comentários sobre o código

* Foi criado uma **__struct__** basica para representar os pontos;

* Com os pontos coletados, foi feito uma varedura entre os pixels da area informada e atribuido o negativo a partir da operação **__image.at<uchar>(i, j) = 255 - image.at<uchar>(i, j);__**;

A Figura 1 ilustra o resultado obtido:

[#image-result1]
.resultado_pratica1.png
image::resultado_pratica1.png[Resultado da Prática 1]

---

=== Prática 2 - Manipulando pixels em uma imagem (trocaregioes.cpp)

Foi desenvolvido um programa chamado "trocaregioes.cpp" com base no código "pixels.cpp" disponibilizado https://agostinhobritojr.github.io/tutorial/pdi/pixels.html[aqui]. Esse novo programa realiza uma transformação na imagem fornecida, trocando os quadrantes dispostos em diagonal. O usuário fornece uma imagem, e o programa divide-a em quatro quadrantes iguais. Em seguida, os quadrantes localizados em posições diagonais são trocados entre si, gerando uma nova composição visual onde a parte superior esquerda se alterna com a inferior direita e a parte superior direita com a inferior esquerda. Essa modificação altera a disposição da imagem, destacando novos detalhes na estrutura visual.

O código utilizado para realizar essa prática esta descrito logo abaixo:

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv) {
    cv::Mat image;
    cv::Rect rect(20, 50, 30, 30);

    image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);
    if (!image.data) std::cout << "nao abriu!" << std::endl;

    // obtendo os quadrantes
    cv::Mat q1 = image(cv::Rect(0,0,image.cols/2,image.rows/2));
    cv::Mat q2 = image(cv::Rect(image.cols/2,0,image.cols/2,image.rows/2));
    cv::Mat q3 = image(cv::Rect(0,image.rows/2,image.cols/2,image.rows/2));
    cv::Mat q4 = image(cv::Rect(image.rows/2,image.cols/2,image.cols/2,image.rows/2));

    cv::Mat RowUp, RowDown, FinalImage;

    cv::hconcat(q4, q3, RowUp); // concatena horizontalmente duas matrizes (images)
    cv::hconcat(q2, q1, RowDown); // concatena horizontalmente duas matrizes (images)
    cv::vconcat(RowUp, RowDown, FinalImage); // concatena verticalmente duas matrizes (images)
    
    cv::namedWindow("janela", cv::WINDOW_AUTOSIZE);

    cv::imshow("janela", FinalImage);
    cv::waitKey();
    return 0;
}
----

==== Comentários sobre o código

* A imagem foi separada em 4 sub-imagens definindo as imagens de cada quadrante;

* Em seguida foi feito a concatenação das duas imagens do quadrante na horientação horizontal do **q4->q3** e do **q2->q1**;

* Por fim é feito a concatenação vertical das duas linhas concatenadas gerando a imagem com os quadrantes diagonais trocados.

A Figura 2 ilustra o resultado obtido:

[#image-result2]
.resultado_pratica2.png
image::resultado_pratica2.png[Resultado da Prática 2]

=== Prática 3 - Filtragem no domínio espacial I - Convolução

==== Exercicio 1 - (convolucao2.cpp)

Neste exercício, foi desenvolvido um programa para realizar a convolução com o filtro da média, aplicando máscaras de tamanhos 11×11 e 21×21 pixels. Os resultados obtidos foram comparados com os do filtro de tamanho 3×3 pixels.

Foi criado uma função para criar as máscaras com a dimensão gênerica, comos podemos ver no código abaixo:

[[create_mask, Fun]]
[source,cpp]
.convolucao2.cpp
----
float* create_mask(int dimensao,std::string tipo){
  float** matriz = new float*[dimensao*dimensao];
  int limit_inf =(dimensao-1)/2;
  int limit_sup = (dimensao-1)/2;
  int elemento_central_laplacian = 0;
  

  for (int i = 0; i < dimensao; i++) {
        matriz[i] = new float[dimensao];
  }

  for(int i=0; i < dimensao; i++){
    for(int j=0; j < dimensao; j++){
      if(tipo == "media"){
        matriz[i][j] = 1.0/(dimensao*dimensao);
      }else if(tipo == "gauss"){
        float sigma = dimensao / 3.0;
        float x = i - dimensao / 2;
        float y = j - dimensao / 2;
        matriz[i][j] = exp(-(x * x + y * y) / (2 * sigma * sigma)) / (2 * M_PI * sigma * sigma);
      }else if(tipo == "horizontal"){
        if (j == 0) {
          matriz[i][j] = -1;
          if(i == (dimensao-1)/2){
            matriz[i][j] = -2;
          }
        } else if (j == dimensao-1) {
          matriz[i][j] = 1;
          if(i == (dimensao-1)/2){
            matriz[i][j] = 2;
          }
        } else {
          matriz[i][j] = 0;
        }
      }else if(tipo == "vertical"){
        if (i == 0) {
          matriz[i][j] = -1;
          if(j == (dimensao-1)/2){
            matriz[i][j] = -2;
          }
        } else if (i == dimensao-1) {
          matriz[i][j] = 1;
          if(j == (dimensao-1)/2){
            matriz[i][j] = 2;
          }
        } else {
          matriz[i][j] = 0;
        }
      }else if(tipo == "laplacian"){
        if(j < limit_inf || j > limit_sup){
          matriz[i][j] = 0;
        }else{
          matriz[i][j] = -1;
          elemento_central_laplacian += 1;
        }
      }
    }
    std::cout << limit_inf << " " << limit_sup << std::endl;
    if(i < (dimensao-1)/2){
      limit_inf -= 1;
      limit_sup += 1;
    }else{
      limit_inf += 1;
      limit_sup -= 1;
    }
  }

  if(tipo == "laplacian"){
    elemento_central_laplacian -= 1;
    matriz[(dimensao-1)/2][(dimensao-1)/2] = elemento_central_laplacian;
  }


  float* vetor = transform_matriz_for_vetor(matriz, dimensao);
  
  // liberando memoria da alocação da matriz
  for (int i = 0; i < dimensao; i++) {
    delete[] matriz[i];
  }
  delete[] matriz;

  return vetor;
}
----

Com isso foi usado o código fornecido pelo exemplo e feito as seguintes alterações para aplicar a convolução na imagem capturada pela webcam:

[[main, Fun]]
[source,cpp]
.convolucao2.cpp
----
int main(int, char* argv[]) {
  int dimensao = std::stoi(argv[1]);

  if (dimensao % 2 == 0){
    return -1;
  }

  cv::VideoCapture cap;
  int camera;
  float* media = create_mask(dimensao, "media");
  float* gauss = create_mask(dimensao, "gauss");
  float* horizontal = create_mask(dimensao, "horizontal");
  float* vertical = create_mask(dimensao, "vertical");
  float* laplacian = create_mask(dimensao, "laplacian");
  imprimir_vetor(laplacian, dimensao);

  cv::Mat frame, framegray, frame32f, frameFiltered;
  cv::Mat mask(dimensao, dimensao, CV_32F);
  cv::Mat result;
  double width, height;
  int absolut;
  char key;

  camera = cameraEnumerator();
  cap.open(camera);

  if (!cap.isOpened()) 
    return -1;

  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);

  cv::namedWindow("filtroespacial", cv::WINDOW_NORMAL);
  cv::namedWindow("original", cv::WINDOW_NORMAL);

  mask = cv::Mat(dimensao, dimensao, CV_32F, media);

  absolut = 1;  // calcula absoluto da imagem

  for (;;) {
    cap >> frame;  // captura nova imagem da camera
    cv::cvtColor(frame, framegray, cv::COLOR_BGR2GRAY);
    cv::flip(framegray, framegray, 1);
    cv::imshow("original", framegray);
    framegray.convertTo(frame32f, CV_32F);
    cv::filter2D(frame32f, frameFiltered, frame32f.depth(), mask, cv::Point(1, 1), cv::BORDER_REPLICATE);
    if (absolut) {
      frameFiltered = cv::abs(frameFiltered);
    }

    frameFiltered.convertTo(result, CV_8U);

    cv::imshow("filtroespacial", result);

    key = (char)cv::waitKey(10);
    if (key == 27) break;  // tecla ESC pressionada!
    switch (key) {
      case 'a':
        absolut = !absolut;
        break;
      case 'm':
        mask = cv::Mat(dimensao,dimensao, CV_32F, media);
        printmask(mask);
        break;
      case 'g':
        mask = cv::Mat(dimensao, dimensao, CV_32F, gauss);
        printmask(mask);
        break;
      case 'h':
        mask = cv::Mat(dimensao, dimensao, CV_32F, horizontal);
        printmask(mask);
        break;
      case 'v':
        mask = cv::Mat(dimensao, dimensao, CV_32F, vertical);
        printmask(mask);
        break;
      case 'l':
        mask = cv::Mat(dimensao, dimensao, CV_32F, laplacian);
        printmask(mask);
        break;
    }
  }
  return 0;
}
----

==== Comentários sobre o código

* Básicamente o que irá mudar no código sera apenas as mascaras de convolução.

A Figura 3 ilustra o resultado obtido:

[#image-result31]
.media.png
image::media.png[Resultado da Prática 3 - exercicio 1]

Com isso, podemos notar que quanto maior a dimensão da máscara, mais intenso o efeito relacionando ao filtro aplicado é maior. em alguns casos isso pode gerar algo até irreconhecivel como os filtros horizontal, vertical e laplaciano de dimensão 21x21.

==== Exercicio 2 - (depthffield.cpp)

Neste exercício, foi implementado um programa chamado depthoffield.cpp com o objetivo de simular uma correção para o efeito de profundidade de campo em imagens digitais, especialmente em cenas sem movimento. O programa inicia capturando um frame do vídeo apresentado, convertendo-o em tons de cinza para facilitar a análise. Em seguida, uma matriz é criada para armazenar os valores máximos dos laplacianos aplicados, que destacam áreas de maior contraste na imagem.

Um filtro laplaciano de tamanho 3×3 pixels é aplicado à imagem em tons de cinza. O resultado é comparado com a matriz de máximos para identificar os pixels que apresentam maior valor de contraste. Esses pixels selecionados são copiados para a imagem de saída, preservando as cores originais da imagem capturada, enquanto o restante da imagem é deixado desfocado. Ao final, a imagem de saída é exibida, destacando as áreas mais nítidas, como uma simulação de profundidade de campo ajustada.

[[depth, Fun]]
[source,cpp]
.depthoffield.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv) {
    // Carregar o vídeo
    cv::VideoCapture cap;
    double width, height;
    cv::Mat frame, framegray, frameFiltered, frame32f, image_final;
    cv::Mat mask(3, 3, CV_32F);
    cv::Mat maximos8U, maximosColor;
    cv::Mat resultado;

    float laplacian[] = {0, -1, 0, -1, 4, -1, 0, -1, 0};
    mask = cv::Mat(3, 3, CV_32F, laplacian);

    cap.open(argv[1]);
    if (!cap.isOpened()) {
        std::cerr << "Erro ao abrir o vídeo!" << std::endl;
        return -1;
    }

    //obtendo as dimensões do video
    width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
    height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

    // Inicializar a matriz de máximos do laplaciano
    cv::Mat maximos = cv::Mat(height, width, CV_32F, cv::Scalar(0));

    while (cap.read(frame)) { // Capturar o frame
        if (frame.empty()) {
            std::cerr << "Erro: Frame vazio!" << std::endl;
            break;
        }

        // Converter o frame para tons de cinza
        cv::cvtColor(frame, framegray, cv::COLOR_BGR2GRAY);
        framegray.convertTo(frame32f, CV_32F);

        // Fazer a convolução com a máscara 3x3 laplaciana
        cv::filter2D(frame32f, frameFiltered, frame32f.depth(), mask, cv::Point(1, 1), cv::BORDER_REPLICATE);

        // Comparar com o valor da matriz dos máximos do laplaciano
        for (int i = 0; i < height; i++) {
            for (int j = 0; j < width; j++) {
                if (frameFiltered.at<float>(i, j) > maximos.at<float>(i, j)) {
                    maximos.at<float>(i, j) = frameFiltered.at<float>(i, j);
                }
            }
        }

        // Converter maximos para o mesmo tipo e número de canais de frame antes de somar
        
        maximos.convertTo(maximos8U, CV_8U);
        cv::cvtColor(maximos8U, maximosColor, cv::COLOR_GRAY2BGR); // Converte para 3 canais

        cv::imshow("Resultado", maximosColor);

        if (cv::waitKey(30) >= 0) break;
    }

    if (cv::imwrite("output_image.jpg", maximosColor)) {
        std::cout << "Imagem salva com sucesso como 'output_image.jpg'" << std::endl;
    } else {
        std::cerr << "Erro ao salvar a imagem!" << std::endl;
    }

    return 0;
}
----

==== Comentários sobre o código

não foi obtido a conversão da cor do video original.

A Figura 4 ilustra o resultado obtido:

[#image-result32]
.output_image.jpg
image::output_image.jpg[Resultado da Prática 3 - exercicio 2]

== Atividades Unidade 2

Na unidade 2 somos introduzidos ao processamento de imagens no dominio da frequencia, onde iniciamos com a **Tranformada Discreta de Fourier**.

=== Prática 1 - Obtendo o espectro de Magnitude

Nessa prática foi obtido o espectro de magnitude da imagem abaixo:

[#image-senoidal]
.senoidal.png
image::senoidal.png[representação de uma senoide]

usando como base o arquivo **dft.cpp**, usando a imagem senoidal tivemos o seguinte resultado:


==== Comentários sobre o resultado

=== Prática 2 - Criando arte com pontilhismo usando o algoritmo de Canny

O pontilhismo é uma técnica de pintura do século XIX, popularizada por Georges Seurat e Paul Signac, que utiliza pequenos pontos de cores puras justapostos para criar imagens. O efeito visual resulta da fusão óptica dessas cores pelo olhar do observador, em vez de pela mistura na paleta. Essa técnica confere luminosidade e vibração às obras, exigindo paciência e precisão do artista.

Usando o algoritmo de Canny para detecção de bordas foi criado o arquivo https://github.com/CarlosG18/pdi_dca0445[cannypoints.cpp] para criar uma forma de realizar uma simulação do pontilhismo computacionalmente. Basicamente foram usados como base para a criação desse arquivo os códigos dos exemplos do **canny.cpp** e **pontilhismo.cpp** https://agostinhobritojr.github.io/tutorial/pdi/canny.html[que estão disponiveis aqui].

==== Etapas do desenvolvimento da solução

basicamente o efeito do pontilhismo é realizado no seguinte trecho:

[source,cpp]
----
for(int k = MIN_LIMIAR; k < MAX_LIMIAR; k+=1){
    canny_generate(k, 0);
    raio -= decremento;
    for (auto i : xrange) {
      std::shuffle(yrange.begin(), yrange.end(), std::default_random_engine(seed));
      for (auto j : yrange) {
        x = i + std::rand() % (2 * JITTER) - JITTER + 1;
        y = j + std::rand() % (2 * JITTER) - JITTER + 1;
        coeficient_canny = border.at<uchar>(y, x); // Índices corretos para acessar o pixel
        if(coeficient_canny != 0){
            cv::Vec3b color = original.at<cv::Vec3b>(x, y); // Obter cor RGB do pixel
            cv::circle(points, cv::Point(y, x), raio, cv::Scalar(color[0], color[1], color[2]), cv::FILLED, cv::LINE_AA);
        }
      }
    }
  }
----

* É percorrido um for onde o valor da variavel k estará sendo acrescentada de uma unidade dentro da faixa do **MIN_LIMIAR** até **MAX_LIMIAR**;
* O valor do k será passado para a função **canny_generate()** onde ela aplica o algoritmo de canny e retorna na matriz **border** os valores de 255 para as bordas detectadas com o valor do limiar passado (k);
* O valor da variavel **raio** é decrementado, começando com um valor alto e com o passar das iterações vai diminuindo, onde se é calculado da seguinte maneira:

[source,cpp]
----
int calcularRaioMax(int largura, int altura) {
    // Dimensões da imagem de referência
    const int largura_ref = 2329;
    const int altura_ref = 3500;
    const int soma_dim_ref = largura_ref + altura_ref;

    // Raio máximo de referência
    const float raio_ref = 20.0f;

    // Calcula o raio máximo proporcional
    return raio_ref * (float)(largura + altura) / soma_dim_ref;
}

MAX_RAIO = calcularRaioMax(width, height);
int faixa = MAX_LIMIAR - MIN_LIMIAR;
decremento = (MAX_RAIO - MIN_RAIO)/float(faixa);
----

A função **calcularRaioMax** calcula o raio max para aquela imagem usando como referencia um parametrização que foi feito usando uma imagem de referencia e vendo que um raio max adequado era de 20. com isso uma proporção é feito com a imagem lida e um novo valor para o raio maximo é calculado e também calculado o valor do decremento que não passa o valor definido na variavel **MIN_RAIO**;

* E por fim é feito o desenho do circulo com o tamanho do raio definido pelo valor da variavel **raio** e obtido as cores da imagem original e replicado na matriz points.

=== Exemplos do pontilhismo digital

[#paisagem]
.paisagem2.jpg
image::paisagem2.jpg[paisagem]

[#paisagem-points]
.paisagem2points.png
image::paisagem2points.png[pontilhismo]

=== Prática 3 - Criando um GIF com Imagens Geradas pelo Algoritmo K-Means

Nesta prática, utilizamos o algoritmo K-Means para segmentar imagens e, em seguida, criamos um GIF com os resultados gerados. O código base foi adaptado de um exemplo disponível online, com a modificação principal de aceitar um número máximo de clusters passado como argumento durante a execução.

==== Código-Fonte do Programa

O código abaixo implementa a execução do algoritmo K-Means em uma imagem de entrada, variando o número de clusters entre 2 e um valor máximo definido pelo usuário. O programa salva uma imagem para cada valor de K.

[source,cpp]
----
#include <cstdlib>
#include <opencv2/opencv.hpp>

void calcularKMeans(const cv::Mat& img, int nClusters, int nRodadas, const std::string& outputPrefix) {
    cv::Mat rotulos, centros;

    // Prepara a matriz de amostras
    cv::Mat samples(img.rows * img.cols, 3, CV_32F);
    for (int y = 0; y < img.rows; y++) {
        for (int x = 0; x < img.cols; x++) {
            for (int z = 0; z < 3; z++) {
                samples.at<float>(y + x * img.rows, z) = img.at<cv::Vec3b>(y, x)[z];
            }
        }
    }

    // Executa o K-Means
    cv::kmeans(samples, nClusters, rotulos,
               cv::TermCriteria(cv::TermCriteria::EPS | cv::TermCriteria::COUNT, 10000, 0.0001),
               nRodadas, cv::KMEANS_PP_CENTERS, centros);

    // Cria a imagem rotulada
    cv::Mat rotulada(img.size(), img.type());
    for (int y = 0; y < img.rows; y++) {
        for (int x = 0; x < img.cols; x++) {
            int indice = rotulos.at<int>(y + x * img.rows, 0);
            rotulada.at<cv::Vec3b>(y, x)[0] = (uchar)centros.at<float>(indice, 0);
            rotulada.at<cv::Vec3b>(y, x)[1] = (uchar)centros.at<float>(indice, 1);
            rotulada.at<cv::Vec3b>(y, x)[2] = (uchar)centros.at<float>(indice, 2);
        }
    }

    // Salva a imagem resultante
    std::string outputPath = outputPrefix + "_k" + std::to_string(nClusters) + ".jpg";
    cv::imwrite(outputPath, rotulada);
    std::cout << "Imagem salva: " << outputPath << std::endl;
}

int main(int argc, char** argv) {
    if (argc != 4) {
        std::cout << "Uso: kmeans entrada.jpg saida_prefixo max_clusters\n";
        return 0;
    }

    int maxClusters = std::atoi(argv[3]);
    if (maxClusters < 2) {
        std::cerr << "Erro: o número máximo de clusters deve ser pelo menos 2." << std::endl;
        return -1;
    }

    int nRodadas = 5; // Número de rodadas do K-Means

    // Lê a imagem de entrada
    cv::Mat img = cv::imread(argv[1], cv::IMREAD_COLOR);
    if (img.empty()) {
        std::cerr << "Erro: não foi possível carregar a imagem." << std::endl;
        return -1;
    }

    // Executa o K-Means para cada número de clusters no intervalo
    for (int nClusters = 2; nClusters <= maxClusters; nClusters++) {
        calcularKMeans(img, nClusters, nRodadas, argv[2]);
    }

    return 0;
}
----

==== Testes Iniciais com o Algoritmo

Antes de criar o GIF, realizamos alguns testes para compreender o comportamento do algoritmo. Foram feitas as seguintes modificações no código:

- O parâmetro `nRodadas` foi ajustado para 1.
- Os centros foram inicializados de forma aleatória, usando o parâmetro `KMEANS_RANDOM_CENTERS` em vez de `KMEANS_PP_CENTERS`.
- Executamos o algoritmo 10 vezes, cada uma com configurações diferentes, e comparamos as imagens produzidas.

==== Análise dos Resultados dos Testes

Os resultados mostraram que as imagens são distintas porque os centros dos grupos são definidos de forma aleatória e apenas uma iteração é realizada. Sem a recalculação dos centros, as imagens apresentaram diferenças significativas entre si, destacando a importância de múltiplas iterações para a convergência do algoritmo.

==== Criação do GIF

Após os testes, utilizamos a biblioteca `magick` para criar um GIF a partir das imagens geradas. O comando utilizado foi o seguinte:

[source,bash]
----
./kmeans entrada.jpg saida_prefixo 15
magick convert -delay 10 -loop 0 saida_prefixo_k*.jpg output.gif
----

Neste caso, o programa gerou 15 imagens, variando o valor de K entre 2 e 15. O comando `magick` então combinou essas imagens em um GIF animado.

==== Resultado Final

O GIF gerado mostra a evolução da segmentação conforme o número de clusters aumenta, ilustrando o funcionamento do algoritmo K-Means.

image::/home/eduardo09/gabriel/ufrn/semestres/2024.2/pdi/pdi_dca0445/labs/uni2/kmeans/build/output.gif[saida do gif]

== Bibliografia ==
[bibliography]
- Stephen Prata. 'C++ Primer Plus'. Addison-Wesley. 1990. 2 ed.
- http://www.cplusplus.com. 'Principal portal de desenvolvimento e referência para programação em C++'.


